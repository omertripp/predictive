\section{Relaxation of Flow Dependencies}~\label{sec:relax1}
Our first relaxation is to allow variables to have different values 
as long as thread local paths are preserved.
Given a trace, $\tau=<\Gamma , \{\tau_{t_1}, \tau_{t_2}, \dots \tau_{t_n} \}, 
O, \theta>$, the main goal of our analysis is to derive a new trace,
  $\tau'=<\Gamma , \{\tau_{t_1}, \tau_{t_2}, \dots \tau_{t_n} \}, O', \theta'>$,
 which reschedules the events from different threads (while preserving 
intra-thread event order) to prove the race. The key insight underlying 
this relaxation is that a thread is allowed to read a different value, 
potentially from a different write, as long as branching decisions 
remain unchanged. Note that we also need to compute the new value 
mapping $\theta'$, because the rescheduling may alter the value every 
variable is assigned to. The computation of the new schedule and new value 
mapping is explained in the following.






%We begin by describing the first relaxation, whereby the dependence structure defined by the original trace is potentially violated while retaining soundness.

\subsection{SSA Form of the Trace}~\label{sec:ssa}
First of all, we rewrite the trace into SSA form, such that every variable is
defined exactly once in the trace. This requirement is a prerequisite for 
the computation of the mapping, in which each variable is mapped to exactly 
one value. Another side effect is that the def/use chains become explicit 
in SSA form, which simplifies the following analysis steps.

\tool\ handles local assignments and heap accesses differently.
\begin{itemize}
\item {\bf Local Assignment\ } The SSA form for local assignments 
resembles the static SSA form in compiler optimizations, 
except that loops and recursions are fully resolved in the trace, 
obviating the need for {\sf Phi} nodes\footnote{While \tool in fact uses
Phi nodes in the second relaxation, for simplicity during discussion, we 
do not assume Phi nodes in this stage.} . More concretely, we replace the 
variable $v$ defined in an event, as well as the following uses of the 
definition, to a new variable $v^{id}$, where $id$ is the unique id 
of the event. The uniqueness of the id guarantees that no two events 
define the same variable, i.e., each variable is defined exactly once.  
In Figure~\ref{fig:running2}, for example,
the local variable $x$ defined at line 4 is renamed as $x^4$.
% where the line number is also used as event id,  the local variable $x$ defined at line 4 is renamed as $x^4$ in the trace, while $x$ defined at line 9 is renamed as $x^9$, which is used in the following two events.  At line 5, where the object $o3$ is created,  we define a reference variable $w^5$.  Internally,  the object $o3$ is encoded as a unique integer that indicates its heap address.
\item {\bf Heap accesses\ } The def/use relation between local heap accesses 
can be determined locally. Therefore, we treat them in the same way as 
local assignments. The def/use relations between shared heap accesses 
are more complex. We may link a read with different writes under different 
schedules, e.g., the read of {\tt y} at line 4 in Figure \ref{fig:running} can 
be from before line 1, line 1, or line 3. Therefore, we introduce two symbols to represent the shared read and shared write respectively and use them 
to reason about the possible options.
%establish different links flexibly. 
The details are as follows. 
\begin{itemize}
\item {\bf Local Heap Accesses\ } Given the write $x.f=y$ to a local heap 
location at event $e_{id}$,  we introduce a fresh local variable 
{\tt $l^{id}_{o.f}$} ($o$ is the runtime object referenced by $x$) to 
replace $x.f$. We also replace the uses of the location $o.f$ accordingly.
Here  the subscript $o.f$ is interpreted as a heap location, i.e., the 
field $f$ of the object $o$. Consider the example in 
Figure~\ref{fig:running2}. At lines 6-7, we replace the local heap 
accesses as the local variable $l^6_{o3.f}$.
%An assumption here is the uses and the definition still refer to the same base object $o$ in the predicted run, which is enforced through the constraint specification %(Section~\ref{sec:relax1}).
\item  {\bf Shared Heap Accesses\ }  Given the write $x.f=y$ or the read $y=x.f$ of a shared location at event $e_{id}$, we introduce two symbols, $W^{id}_{\tt o.f }$ and $R^{id}_{\tt  o.f }$ respectively, where $o$ is the runtime object referenced by $x$. Similarly, the subscript $o.f$ is interpreted as a heap location, i.e., the field $f$ of the object $o$. Note that in local heap encoding, 
both read and write are bounded to the same variable, whereas in shared
heap encoding, we use different variables to denote read and write, allowing
the solver to reason about the different dataflow.
\end{itemize}
We use the heap location such as $o.f$ in the symbolic form of heap accesses.
 An underlying assumption is that the heap location remains unchanged, 
which we ensure through additional constraints (Section~\ref{sec:relax1}).
\end{itemize}


% Similar to the local heap accesses, an assumption for the correlation is that the writes and reads still refer to the same base object $o$ in the predicted run, which we guarantee by specifying additional constraints (Section~\ref{sec:relax1}). 

% We could encode the question of shared versus local accesses as additional constraints (requiring that a variable be accessed by more than one thread), but that would be more complicated and less efficient.


%\paragraph{Basic Encoding: Local Accesses}
%
%The fundamental encoding transformation is to induce Static Single Assignment (SSA) form on the raw trace, such that
%a variable is defined exactly once. In this way, , and encoding of trace events as constraints is simplified. As an illustration, trace
%\begin{quote}
%	{\tt 1: x=1; 2: x<3; 3: x=3;} \\
%	{\tt 4: y=1;} \\
%	{\tt 5: z=x+y}
%\end{quote}
%becomes
%\begin{quote}
%	{\tt 1: x$^1$=1; 2: x$^1$<3; 3: x$^3$=3;} \\
%	{\tt 4: y$^4$=1;} \\
%	{\tt 5: z$^5$=x$^3$+y$^4$}
%\end{quote}
%(For readability, we version variables according to the line number of their definition.)



%%TODO update the intro+moti, make sure the same style
\begin{figure}
{\small
\centering
\begin{tabular}{ll|l}
\multicolumn{3}{c}{{\tt {\bf s1} = new();//$o1$}} \\
\multicolumn{3}{c}{{\tt {\bf s2} = new();//$o2$}} \\
\multicolumn{1}{c}{$T_1$} & \multicolumn{1}{c}{$T_2$}  &  \multicolumn{1}{c}{$Trace$}\\
{\tt 1: {\bf s1}.f=3; } &  & {\tt $W^{1}_{o1.f}$=3;}\\
{\tt 2: {\bf s2}.f=1; } &  & {\tt $W^{2}_{o2.f}$=1;}\\
{\tt 3: {\bf s1}.f=2; } & & {\tt $W^{3}_{o1.f}$=2;} \\
& {\tt 4: x=0;} & {\tt $x^4$=0;}\\
& {\tt 5: w=new();//$o3$} & {\tt $w^5$=$o3$;}\\
& {\tt 6: w.f=10;}  & {\tt $l^6_{o3.f}$=10;}\\
& {\tt 7: z=w.f;} & {\tt $z^7$=$l^6_{o3.f}$;}\\
& {\tt 8: y={\bf s1}.f;} & {\tt $y^8$=$R^8_{o1.f}$;}\\
& {\tt 9: x=y+z;} & {\tt $x^9$=$y^8$+$z^7$;}\\
& {\tt 10: if(x>11)}& {\tt if($x^9$>11)}\\ 
& {\tt 11: \ \ {\bf s2}.f=x;}  & {\tt $W^{11}_{o2.f}$=$x^9$;}\\
\end{tabular}
\caption{Running Example (shared variables are in bold font, the line number is used as the event id). }
\label{fig:running2}
}
\end{figure}

 
%\begin{figure}
%\centering
%\begin{tabular}{l|l}
%\hline
%\multicolumn{1}{c}{$Trace$} & \multicolumn{1}{c}{$SSA \ form \ of\   Trace$} \\
%\hline
%{\tt 0: {\bf x}=0} &  {\tt 0: $W^0_x$=0}    \\
%{\tt 1: {\bf y}=0} &   {\tt 1: $W^1_y$=0}   \\
%{\tt 2: s=0} &  {\tt 2: $s^2$=0}   \\
%{\tt 3: i=1} &     {\tt 3: $i^3$=1}   \\
%{\tt 4: i<2} &    {\tt 4: $i^3$<3} \\
%{\tt 5: s=s+i} & {\tt 5: $s^5$=$s^2$+$i^3$}   \\
%{\tt 6: i=2} &       {\tt 6: $i^6$=2}  \\
%{\tt 7: i<2} &      {\tt 7: $i^6$<3}  \\
%{\tt 8: {\bf y} = s;} &  {\tt 8: $W^{8}_y$ = $s^5$;}  \\
%{\tt 9: {\bf y} > 2}  &    {\tt 9: $R^{9}_y$ > 2} \\
%{\tt 10: print({\bf x});} &  {\tt 10: print($R^{10}_x$);}  \\
%\end{tabular}
%\caption{Trace}
%\label{fig:t4running2}
%\end{figure}

%Figure~\ref{fig:t4running2} exemplifies a trace and its SSA form, where the trace is generated from the program in Figure~\ref{fig:running2}.
%Each label in  Figure~\ref{fig:t4running2} on the left hand denotes the id of the event. As seen, event $e_5$ uses the variable $s^2$ defined at event $e_2$ and defines the variable $s^5$, which is used at $e_8$. Reads and writes of shared variables are denoted in the special form explained above (e.g.: $W^{8}_y$ and  $R^{9}_y$).





\subsection{Constraint System}~\label{sec:constraints}
Based on the SSA form of trace $\tau$, we build the constraints to 
compute a new trace $\tau'$ with a new schedule $O'$ and a new 
value mapping $\theta'$. Consider the example in Figure~\ref{fig:running2}. 
In the original trace $\tau$, the event $e_8$ reads the value of 
2 from $e_3$.  Existing 
approaches enforce the same value dependence between $e_3$ and $e_8$.
 Therefore, $e_{11}$ must happen after $e_2$ and the race between 
them is missed.
Our analysis allows event $e_8$ to read from $e_1$, producing the new 
value mapping $\theta'(y^8)=3$. Accordingly, at $e_9$ the value mapping 
for $x^9$ is also updated as 13 ($\theta'(y^8)$=3, $\theta'(z^7)=10$), 
enabling the same true branch at line 10. Finally, the 
events $e_2$ and $e_{11}$ are scheduled to run concurrently.  The 
relaxation needs to respect a set of constraints, which we explain in 
the following. We omit the synchronization constraints as they are well 
explained in~\cite{yannis, pldi14}.


%Having explained how the trace is encoded, we now describe in detail how constraints are derived from the trace, such that any permutation considered by the analysis is guaranteed to represent a feasible execution schedule.

{\bf Race Condition\ } An even pair 
($e_i$, $e_j$) forms a race iff (1) $e_i$ and $e_j$ access a shared
location $\ell$, (2) at least one of them writes $\ell$, and (3) $e_i$ and $e_j$ run concurrently (being associated with different threads). We refer to 
the candidate pair throughout this section as (candidate) \emph{racy events}.  

We first identify all candidate pairs.
%that access the same location from different threads (and at least one is a write). 
We then check each pair separately.  The checking is achieved by encoding 
all necessary constraints.  The first constraint asserts the
concurrency:
%feasibility 
%f the concurrent execution of the racy events: 
$O'(e_i) = O'(e_{j})$.
%In Figure~\ref{fig:running2}, the race condition for the race pair, ($e_2$, $e_{11}$), is $O'(e_2)=O'(e_{11})$

{\bf Intra-thread Constraints\ } Given racy events $e_i$ and $e_j$, suppose 
$e_i$ is after $e_j$ in the original trace $\tau$. Our analysis reschedules 
the events in the prefix up to $e_i$, so that $e_i$ and $e_j$ can run 
concurrently. We refer to the prefix as $prefix(\tau, e_i)$. Throughout 
this section, we only consider events in the prefix. 

Preservation of the event sequence (up to $e$) for each thread requires 
the following intra-thread constraints:

\begin{itemize}
\item {\bf Control Flow Constraints\ } The branches in the predicted run 
should take the same decisions as in the original trace so that each thread 
reproduces the same sequence of events\footnote{We allow path differences in
the second relaxation. This is to avoid presenting the encoding
of both relaxations together, which is overly complex.} 
%the encodings of both relaxation together, .  
%Specifically, we only need to reason about the branches prior to $e_i$.

Without loss of generality, we assume the branch event $e_k$ is in the form of $if(x<y)$. Then  we require that 
$$
\bigwedge_{e_k \in prefix(\tau,e_i) \wedge  inst^{e_k}=if(x<y).\ }  \theta'(x)<\theta'(y) 	\equiv \theta(x)<\theta(y)
$$ 
The constraint specifies that the branch condition should be evaluated as 
the same boolean value in the predicted run $\tau'$ as in the original 
trace $\tau$.
 Importantly, Unlike existing analyses \cite{yannis,pldi14}, we do not 
pose the requirement that the values flowing into branching statements 
remain the same, but adopt the relaxed requirement that 
the branch outcome remains the same.
%the evaluation 
%of branching expressions remains the same. 
Consider the example in Figure~\ref{fig:running2}, given the branch 
if($x^9$$>$11) at $e_{10}$, the original mapping is $\theta(x^9)=12$. We allow  
a different value mapping, e.g., $\theta'(x^9)=13$, which retains the 
same truth value for the branch.
\item {\bf Intra-thread Order Constraints\ } The events in the sequence 
should follow the same order as in the original trace. More formally, 
we require that
$$
\begin{array}{rl}
\forall e_m, e_n \in prefix(\tau,e_i), s.t., & t^{e_m} = t^{e_n}. \\
 O(e_m) < O(e_n)\  & \Rightarrow O'(e_{m}) < O'(e_{n}) 
\end{array}
$$ 
This constraint specifies that two events from the same thread should 
follow the same order as reflected by the ids of the events.
\item {\bf Intra-thread Value Constraints\ } The value mapping of the 
variables should not contradict the constraints imposed by individual 
instruction.   Without loss of generality, suppose the instruction is 
a local assignment in the form of $x=y+z$, then we require that
$$
\bigwedge_{e_k \in prefix(\tau,e_i) \wedge inst^{e_k}=x=y+z}\
	\theta'(x)=\theta'(y)+\theta'(z)
$$
Recall that every variable may obtain a different value in the new 
trace $\tau'$ because it may read from some shared variable affected by 
the rescheduling. The constraint specifies that, the variables should 
be re-assigned to some values that are consistent with the instruction. 
Consider the example in Figure~\ref{fig:running2}, given the 
event $x^9=y^8+z^7$ at line 9, if the mappings $\theta'(y^8)$ and 
$\theta'(z^7)$ change to 3 and 10 respectively, the 
mapping $\theta'(x^9)$ should change to 13 to be consistent. 
%In the above, we use the local assignment event for demonstration, in general, the intra-thread value constraints should also be specified for the {\sf  heapr/heapw} events.
\end{itemize}



%Rescheduling through Relaxation of Flow Dependencies
{\bf Inter-thread Value Constraints for Relaxation\ } 
%We now move to 
%the
%first novel feature of \tool, which is its 
%explain our ability to explore execution schedules that depart from the 
%value flow exhibited in the original trace. More precisely, 
%\tool\ is able to relax value flow dependencies in the original trace:  a 
%read access may read a different value from other write events, as 
%long as the read value enforces feasibility of the following execution.
% This is strictly beyond the coverage potential of existing predictive analyses, which restrict trace transformations to ones where any read access must read the same  value (often from the same write event) as in the original trace. 

To ensure feasibility under value relaxation
% of flow dependencies, 
we need to ensure the flow between read and write with some execution schedule. 
For example, in Figure \ref{fig:running2}, for the read at $e_8$ to read 
from the write t $e_1$, we need a schedule where 
$e_8$ happens after $e_1$ and other writes such as $e_3$ do not interleave them.


% $R_{\tt y}^4={\tt y}^1 \wedge O_1 < O_4 < O_3$ specifies that in a schedule , the $R_{\tt y}^4={\tt y}^1$.


In general, the constraint formula, given read $R^{m}_{\ell}$ of location 
$\ell$ at event $e_m$ with set ${\cal W}$ the matching write events 
(i.e., events including write access to $\ell$), takes the following form:
$$
{\small
\begin{array}{rll}
\bigvee_{e_n \in {\cal W}} &  & (\theta'(R^{m}_{\ell}) = \theta'(W^{n}_{\ell})) \\
&		\bigwedge 	&  O'(e_n) < O'(e_m) \\
&		\bigwedge_{e_p \in {\cal W} \setminus \{ e_n \}} & (O'(e_p) < O'(e_n) \vee O'(e_m) < O'(e_p))
\end{array}
}
$$
This disjunctive formula iterates over all matching write events, and requires 
for each write that (i) it occurs prior to the 
read event $O'(e_n) < O'(e_m)$ and (ii) all other write events either 
occur before $O'(e_p) < O'(e_n)$ it or after the read 
event $O'(e_m) < O'(e_p)$.

An important concern that arises due to value relaxation 
%of flow dependencies 
is that heap accesses may change their meaning, i.e., they involve 
different base objects and no longer match with each other. As an 
illustration, we refer to Figure \ref{fig:heapAccess}. While the read at 
event $e_7$ appears to match the write at $e_5$, this is conditioned 
on the read at $e_6$ being linked to the assignment at $e_4$ (
object $o_2$ is the object denoted by $z$ according to the source code). 
Suppose event $e_6$ reads from $e_3$ due to the relaxation. Then $e_7$ and 
$e_5$ should not share the same base object. 
%Even worse, we do not know which events $e_7$ matches, because the base object is no longer known.



\begin{figure}
{\small
	\centering
	\begin{tabular}{ll}
		\hline
		\multicolumn{1}{c}{$T_1$} & \multicolumn{1}{c}{$T_2$} \\
		\hline
		{\tt 1: $x^1$ = new();// creates o1} & \\
		{\tt 2: $x^2$= new();// creates o2} & \\
		{\tt 3: $W^3_{y}$ = $x^1$;} & \\
		{\tt 4: $W^4_{y}$ = $x^2$;} & \\
		{\tt 5: $W^5_{o2.f}$ = 5;} & \\	
		& {\tt 6: $z^6$ = $R^6_{y}$;} \\
		& {\tt 7: $w^7$ = $R^7_{o2.f}$;} \\
	\end{tabular}
	\caption{\label{fig:heapAccess} A trace. The source code of line 7 is
``{\tt w=z.f}''.}
}
\vspace{-0.15in}
\end{figure}

{\bf Invariant Base Object Constraints\ } To address this challenge, 
we enhance the constraint system with the requirement that heap objects 
that are dereferenced in field accesses before the racy events retain 
their original address in the predicted trace. This provides two
guarantees: First, matching heap access events in the original trace are 
guaranteed to also match in the predicted trace. Second, candidate races 
in the original trace remain viable in the predicted trace as they still 
refer to same location. 
%Third, sharing between threads of heap locations 
%remains unchanged because each location is accessed by the same number 
%of threads given that the base object is the same. 
%XZ: I commented out the third as I think it is obvious and not that useful.





%Note that, the resolution of the virtual method call is modeled as the branch events that check the type of the target object, for which the constraints naturally guarantee the branch to take the same decision, i.e., the call to be resolved to the same method implementation.

%Finally, in a practical setting involving virtual method calls, call-site resolutions are the same across the original and predicted traces. 
%Notice that in this setting, we consider as relevant not only the targets of field dereferences but also the targets of virtual method invocations.

Formally, we require that
$$
\bigwedge_{ e_k \ has\  x.f \wedge e_i \in prefix(\tau,e_i) }\
	\theta'(x) \equiv  \theta(x)
$$
%where ${\sf env}$ is the state mapping from local variables to their value and $\sigma(t,\tau'')$ 
%(resp. $\sigma(t',\tau'')$) is the state arising at trace $t$ (resp. $t'$) immediately before event $\tau''$.


This constraint fixes that all heap dereferences  prior to the racy event retain their original base object as in the original trace $\tau$. 
The array accesses are handled similarly to the field accesses, but we need to additionally require the index variable to be the same as in the original trace.
In addition, for local heap accesses, in case that the base variable reads a local object from a shared reference variable, the base variable may change due to the rescheduling. We also fix the base variable as a constant, in order to ensure the validity of the SSA encoding of the local heap accesses and preserve the def/use chains among them. The constraint is specified during the SSA encoding.




By sending the above constraints to a solver, we compute the necessary schedule orders among the events as well as the mapping of the variables. The necessary schedule orders define a partial order among the events, which permit a set of schedules that define the complete order that complies with it.


