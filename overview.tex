\section{Technical Overview}\label{Se:techoverview}

In this section, we walk the reader through a detailed technical description of our approach based on the example in Figure \ref{fig:running}. 
%
As input, we assume (i) a program $P$ as well as (ii) a trace of $P$ recorded during a dynamic execution.

% in Static Single Assignment (SSA) form, such that every variable is defined exactly once.

\subsection{Preliminaries}
To facilitate our presentation, we first introduce some terminologies used throughout this paper. At the high level, a trace is a sequence of events recorded during the observation run.




{\bf Event\ } An event, $e=<t, id, inst, map>$, is a concrete representation that captures the details about the runtime execution of a static instruction $inst$.

\begin{itemize}
\item $t$ refers to the thread that issues the event, denoted as $t^e$.
\item  $id$ refers to the id associated with each event, denoted as $i^e$. The key property of  $id$ is {\em uniqueness}, i.e., any two events in the trace own different ids. The important property of $id$ is {\em monotonicity}, i.e.,  the events from the same thread should own the strictly increasing ids. Throughout this paper, we use  the index of an event in the trace as its id, which satisfies the above properties. Throughout this paper, we use the event $e$ and its id $id$ interchangeably in our notation given the one-to-one correspondence between $e$ and $id$. Thus, for example, if the index of event $e$ is 3, then $t^e$ and $t^3$ refer to the same thread.
\item $inst$ is the static instruction. The instructions are three-address instructions involving at most three operands, which modern compilers commonly support.  Specifically, we are interested in the types of instructions listed in Table~\ref{Ta:syntax}. When the variable does not appear on the left hand of an equation, such as $y$ in $x.f=y$, it may refer to a variable, a constant or event object creation expression $new (...)$.  The $bop$ stands for the binary operator, which may refer to $+, -, *, /, \%, \wedge, \vee$ in the assignment, or refer to $<, >, =, \wedge, \vee$ in the branch. The target of the branch event is not important in our scope, therefore, we may abbreviate the branch instruction as the boolean expression afterwards. The listed instructions suffice to represent all trace events of interest. This is because a concrete finite execution trace can be reduced to a straight-line loop-free intraprocedural path program (argument passing modeled via assignments to fresh variables). This standard form of simplification preserves all the data-race-related information contained in the original trace. 
\item $map$ is a mapping from live expressions at the current event to their value (and thus a partial mapping from expressions to values). Live expressions include program variables, object fields, boolean expressions, etc. We use the notation $\lsyn exp \rsyn^e$ to retrieve the value associated with expression $exp$ at $e$.

maps the variable in the instruction to the runtime values. The map stores the value for each variable observed in the dynamic run. For simplicity, we use the notion $\lsyn x \rsyn^e$ to retrieve the value associated with the variable $x$ in $e$. 
\end{itemize}

%Specially, $\lsyn x.f \rsyn^e$ returns the location of $x.f$ (rather than  the value stored in the location), which is denoted as a pair $(\lsyn x \rsyn^e, f)$.

\begin{table}
	\begin{center}
		\begin{tabular}{rcl}
			\multicolumn{1}{l}{{\tt s} $::=$} & & \\
			{\tt y = x.f} & $|$ & {\bf (heapr)} \\ 
			{\tt x.f = y}  & $|$ & {\bf (heapw)} \\ %\ $|$\ {\tt x.f = $c$}\
			{\tt z = x $bop$ y}\  & $|$ & {\bf (assign)} \\ %$|$\ {\tt z = $c$} $|$ {\tt z = new()}
			{\tt if (x $bop$  y) goto ...} & $|$ &  {\bf (branch)} \\
			{\tt lock(l)}\ $|$\ {\tt unlock(l)}  & $|$& {\bf (sync)} \\
			{\tt fork(t)}\ $|$\ {\tt join(t)}$|$ {\tt begin(t)}\ $|$\ {\tt end(t)} &  & {\bf (thread)}
		\end{tabular}
	\end{center}
	\caption{\label{Ta:syntax}Language syntax}
\end{table}


{\bf Trace \ } 
We propose the projection operation and domains to facilitate the reasoning of the trace.
\begin{itemize}
\item projection operation  ``$|$'': $\tau|t$ contains only the (ordered) events from the thread $t$; $\tau|l$ contains the events involving the location $l$; $\tau|i$ contains only the event of which the id equals $i$; $\tau|\leq e$ denotes the prefix of $e$, i.e., the events preceding the event $e$; $\tau|\geq e$ denotes the events after $e$; $\tau|>=e_1\wedge <=e_2$ denotes the events between $e_1$ and $e_2$.
\item sets: $\mathcal{T}$ denotes the set of threads involved;  $\mathcal{L}$ denotes the set of memory locations involved; 
$\mathcal{SV}$ denotes the set of shared variables, which reference the shared locations, the shared location $l$ can be judged by counting the number of threads in $\tau|l$;  $\mathcal{E}$ denotes the set of events involved.
\end{itemize}






%We make use of the following helper functions:
%\begin{itemize}
%	\item ${\sf proj}\ t\ i$ projects trace $t$ onto all transitions involving thread $i$.
%	\item $t[k]$ obtains the $k$th transition within trace $t$.
%	\item ${\sf index}\ t\ \tau$ retrieves the index, or offset, of transition $\tau$ within trace $t$. When simply writing
%	${\sf index}\ \tau$ (while omitting the trace parameter) we refer to the index of $\tau$ within the original trace. 
%	\item ${\sf pre}\ t\ \tau$ is the prefix of trace $t$ preceding transition $\tau$. For the suffix beyond $\tau$, we 
%	use ${\sf post}\ t\ \tau$. Finally, ${\sf bet}\ t\ \tau_1\ \tau_2$ returns the transitions delimited by $\tau_1$ and $\tau_2$.
%\end{itemize}

%Throughout this paper, we assume a standard operational semantics, which defines (i) a mapping ${\sf thr}$ between
%execution threads, each having a unique identifier $i \in \mathbb{N}$, and their respective code, as well as (ii) per-thread stack and shared heap memory. 

%The code executed by a given thread follows the syntax in Table \ref{Ta:syntax}. The text of a program is a sequence of zero or more method declarations, as given in the definition of symbol {\tt p}. Methods accept zero or more arguments $\overline{{\tt x}}$, have a body ${\tt s}$, and may have a return value (which we leave implicit). For simplicity, we avoid from static typing as well as virtual methods. The body of a method consists of the core grammar for symbol {\tt s}. We avoid from specifying syntax checking rules, as the grammar is fully standard.

%For simplicity, we assume that in the starting state each thread points to a parameter-free method. In this way, we can simply assume an empty starting state (i.e., an empty heap), and eliminate complexities such as user-provided inputs and initialization of arguments with default values. These extensions are of course possible, and in practice we handle these cases, but reflecting them in the formalism would result in needless complications.

%As is standard, we assume an interleaved semantics of concurrency. A \emph{transition}, or \emph{event}, is of the form
%$\sigma \stackrel{i / {\tt s}}{\longrightarrow} \sigma'$, denoting that thread $i$ took an evaluation step
%in prestate $\sigma$, wherein atomic
%statement {\tt s} was executed, which resulted in poststate $\sigma'$. We refer to a sequence of transitions from
%the starting state to either an exceptional state (e.g., due to null dereference) or a state where all the threads have 
%reduced their respective code to $\epsilon$ as a \emph{trace}.



%TODO this section is inconsistent with others. change it!
\subsection{Constraint System}

We begin with an explanation of the encoding process. The resulting formula is provided in Figure \ref{fig:encoding}. We describe the conjuncts comprising the formula one by one.

\begin{figure*}
	\begin{center}
$$
	\begin{array}{rcl}
	& \left( O_1 < O_2 < O_3 \wedge O_4 < O_5 \wedge O_4 < O_7 \right) & \textbf{(program order)} \\
\bigwedge & \left( W_{\tt x}^0 = 0 \wedge W_{\tt y}^0 = 0 \wedge W_{\tt z}^0 = 3 \wedge W_{\tt y}^1 = 3 \wedge 
	W_{\tt x}^2 = 1 \wedge W_{\tt y}^3 = 5 \right) & \textbf{(variable definitions)} \\
\bigwedge & \left(		(R_{\tt y}^4=W_{\tt y}^0 \wedge O_4 < O_1) \vee	
(R_{\tt y}^4=W_{\tt y}^1 \wedge O_1 < O_4 < O_3) \vee
(R_{\tt y}^4=W_{\tt y}^3 \wedge O_3 < O_4)
		\right) & \textbf{(thread interference)} \\
\bigwedge & R_{\tt y}^4 > 2 \equiv {\bf true} & \textbf{(path conditions)} \\
\bigwedge & t^2 \neq t^5 \wedge (2\ writes\ {\tt x} \vee 5\ writes\ {\tt x}) \wedge O_2 = O_5 & \textbf{(race condition)}
	\end{array} 
$$
\end{center}
\caption{\label{fig:encoding}\tool\ encoding of the trace in Figure \ref{fig:running} as a constraint system}
\end{figure*}

\paragraph{Program Order} The first set of constraints reflects ordering constraints between program statements. We use the symbol $O_i$ to denote the $i$th program statement, which yields the following formula for Figure \ref{fig:running}:
$$
	O_1 < O_2 < O_3 \wedge O_4 < O_5 \wedge O_4 < O_7
$$
That is, the first 3 statements are totally ordered, and the {\tt if} statement executes before the body (either $O_5$ or $O_7$).

\paragraph{Variable Definitions} The next set of constraints, denoted ${\tt w}^i=k$ for local variables and $W_{\tt w}^i=k$ for shared variables, capture variable definitions: Variable {\tt w} is assigned value $k$ at statement $i$. For our running example, we obtain:
$$
	W_{\tt x}^0 = 0 \wedge W_{\tt y}^0 = 0 \wedge W_{\tt z}^0 = 3 \wedge W_{\tt y}^1 = 3 \wedge
			W_{\tt x}^2 = 1 \wedge W_{\tt y}^3 = 5
$$
As an example, ${\tt y}^3 = 5$ denotes that the value assigned to variable {\tt y} 
at line {\tt 3} is $5$.

\paragraph{Thread Interference} To express inter-thread flow constraints, we utilize expressions of the form $R_{\tt z}^i={\tt z}^j$, which denotes that line $i$ reads variable {\tt z}, and the definition it reads comes from line $j$. The resulting formula for our example is
$$
\begin{array}{lcl}
	& & (R_{\tt y}^4=W_{\tt y}^0 \wedge O_4 < O_1)  \\
& \bigvee &
	(R_{\tt y}^4=W_{\tt y}^1 \wedge O_1 < O_4 < O_3) \\
& \bigvee &
	(R_{\tt y}^4=W_{\tt y}^3 \wedge O_3 < O_4)
\end{array}
$$    
Notice, importantly, that the formula combines flow constraints with order constraints, which are essential to determinize the value read at a given statement. As an example, 
$(R_{\tt y}^4=W_{\tt y}^1 \wedge O_1 < O_4 < O_3)$ means that the value of ${\tt y}$ read at 
line {\tt 4} is that set at line {\tt 1} assuming an execution order whereby the first statement executes followed by the fourth then third statements. 

\paragraph{Path Conditions} To preserve path conditions while potentially permitting dependence-violating reordering (e.g., a context switch after line {\tt 1} in Figure \ref{fig:running}), we model explicitly the condition. For the running example (ignoring the statements in red), this yields:
$$
	R_{\tt y}^4 > 2 \equiv {\bf true}
$$
That is, the value of variable {\tt y} read at line {\tt 4} is greater than $2$. Indeed, this constraint is satisfied by the assignments to {\tt y} both at line {\tt 1} and at line {\tt 3}.

\paragraph{Race Condition} The final constraint, forcing the check whether a particular race is feasible, is to demand that two conflicting statements occur at the same time. For the potential race between lines {\tt 2} and {\tt 5}, we obtain:
$$
	O_2 = O_5
$$ 
This asserts that both statements occur simultaneously, which --- together with the other constraints --- guarantees the feasibility of the predicted race if a solution is found for the overall constraint system.

\paragraph{Unexplored Branches} Beyond the encoding steps so far, which focus on the given trace, we can often encode constraints along unexplored branches. In our running example, this is essential to discover the race between lines {\tt 2} and {\tt 7}. 

The conflicting accesses in this case, determined based on static analysis of $P$, are expressed as $O_2=O_7$. In addition, we negate the path condition, thereby obtaining $R_{\tt y}^4 > 2 \equiv {\bf false}$ in place of $R_{\tt y}^4 > 2 \equiv {\bf true}$. 

\paragraph{Constraint Solving} Having conjoined the formuals from the different encoding steps into (i) a global representation of all feasibility constraints (path, ordering, assignment and other constraints) and (ii) the requirement for a given race to occur (expressed as simultaneous execution of the conflicting accesses), we discharge the resulting formula to an off-the-shelf constraint solver, such as Z3 or Yices. If successful, the solver returns a solution for the specified constraints. 

In particular, the solution discloses a feasible trace that gives rise to the race at hand. The trace is identified uniquely via the order enforced in the solution over the variables $O_i$, which represent scheduling order. 
